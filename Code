import fileinput
import random
import selenium
import pandas as pd
from selenium import webdriver as wb
from selenium.webdriver.common.keys import Keys
from selenium import common
import time

path = "https://www.google.com/travel/things-to-do?"

# WebDriver
WD = wb.Chrome(executable_path='chromedriver.exe')
attractions_list = []
# div class ID of the attraction name
tag_name = "skFvHc"
city_from = []
cities = []


def findatt(x):
    # Loads the page.
    WD.get(path)
    # Wait for the load
    WD.implicitly_wait(10)
    # Maximize the window to see it is working.
    # WD.maximize_window()
    # Give a little time to sleep.
    time.sleep(random.uniform(2, 4))
    # Send to the input field the cities.
    input_field = WD.find_element_by_id("oA4zhb")
    input_field.send_keys(x)
    input_field.send_keys(Keys.ENTER)
    # Wait for the page to load.
    WD.implicitly_wait(4)
    while True:
        try:
            time.sleep(random.uniform(4, 6))
            see_all = WD.find_element_by_xpath("//body/c-wiz[2]/div[1]/div[2]/div[1]/c-wiz[1]/div[1]/div[1]/div["
                                               "1]/div[2]/c-wiz[1]/div[1]/div[2]/div[3]/div[1]/div[1]/button[1]/div["
                                               "2]")
            WD.execute_script("arguments[0].click();", see_all)
            WD.implicitly_wait(4)
        except selenium.common.exceptions.NoSuchElementException:
            break
    time.sleep(random.uniform(2, 4))
    # Find the names of attractions for later use.
    attlist = WD.find_elements_by_class_name(tag_name)
    # Add the attractions to a list sequentially.
    for value in attlist:
        attractions_list.append(value.text)
    cf = [x for n in range(len(attlist))]
    print(f"Scraped {len(attlist)} attractions from {x}")
    # Time for breathing and avoid Google IP ban.
    time.sleep(random.uniform(5, 15))
    df1 = pd.DataFrame(attractions_list, columns=['Attractions'])
    df2 = pd.DataFrame(cf, columns=['City'])
    df = df1.join(df2)

    # noinspection PyTypeChecker

    df.to_csv(f'X.csv', index=False, mode='a')

#
def main():
    # Can change file name, but make sure it is in the path.
    with fileinput.FileInput('cities.csv') as f:
        for line in f:
            cities.append(line.rstrip('\n'))
        return cities

# Allows program use in another file.
if __name__ == "__main__":
    main()

# Loop through the list returned and scrape attractions.
for x in cities:
    
    findatt(x)
# If using a small list, it is faster to do this at the end instead of adding to the results each iteration.
# df = pd.DataFrame(attractions_list, columns=['Attractions'])
# df.to_csv(r'\home\james\Desktop\google_attractions.csv', index=False, mode='a')
